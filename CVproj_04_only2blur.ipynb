{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1589,"status":"ok","timestamp":1733920104834,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"K_oUCh39oO18"},"outputs":[],"source":["import os\n","import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","import scipy.io as sio\n","\n","from PIL import Image\n","from skimage.util import img_as_float\n","from skimage.color import rgb2gray\n","from skimage.io import imread, imsave\n","from scipy.io import loadmat\n","from tqdm import tqdm\n","\n","import cv2\n","import urllib.request\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19934,"status":"ok","timestamp":1733920124764,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"nDu3gL6_oO4h","outputId":"4e137058-2fb9-4593-9128-d83250aa5c78"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1733920124764,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"bBCAEqMAolSX","outputId":"b45217a7-4400-491b-b4dc-b3599a17482f"},"outputs":[],"source":["data_dir = \"/content/gdrive/MyDrive/CV/termProject/project_data\"\n","pred_dir = \"/content/gdrive/MyDrive/CV/termProject/predictions\"\n","\n","# Checking if our specified directory exists\n","os.path.exists(data_dir)"]},{"cell_type":"markdown","metadata":{"id":"EXNYpyByEzk2"},"source":["# Train data 불러오기"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1733920124765,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"45xTp2RQoO6y"},"outputs":[],"source":["# train data 불러오는 class\n","\n","class BoundaryDataset(object):\n","    \"\"\"\n","    Project boundary dataset wrapper\n","\n","    Given the path to the root of the dataset, this class provides\n","    methods for loading images and ground truths.\n","\n","    Attributes:\n","\n","    root_dir - the root path of the dataset\n","    data_path - the path of the data\n","    directory within the root\n","    sample_names - a list of names of images\n","    \"\"\"\n","    def __init__(self, root_dir='.', split='train'):\n","        \"\"\"\n","        Constructor\n","\n","        :param root_dir: the path to the root of the custom dataset\n","        :param split: 'train' or 'test'\n","        \"\"\"\n","        self.root_dir = root_dir\n","        self.data_path = os.path.join(root_dir, split)\n","        self.sample_names = self._sample_names(self.data_path)\n","\n","    def __len__(self):\n","        \"\"\"\n","        Get the number of samples in the dataset\n","        :return: the number of samples\n","        \"\"\"\n","        return len(self.sample_names)\n","\n","    @staticmethod\n","    def _sample_names(directory):\n","        names = []\n","        files = os.listdir(directory)\n","        for fn in files:\n","            name, ext = os.path.splitext(fn)\n","            if ext.lower() == '.jpg':\n","                names.append(name)\n","        return names\n","\n","    def read_image(self, name):\n","        \"\"\"\n","        Load the image identified by the sample name\n","        :param name: the sample name\n","        :return: a (H,W,3) array containing the image\n","        \"\"\"\n","        path = os.path.join(self.data_path, f\"{name}.jpg\")\n","        return imread(path)\n","\n","    def load_boundaries(self, name):\n","        \"\"\"\n","        Load the boundaries identified by the sample name\n","        :param name: the sample name\n","        :return: a list of (H,W) arrays, each of which contains a boundary ground truth\n","        \"\"\"\n","        boundary_path = os.path.join(self.data_path, f\"{name}.npy\")\n","        if os.path.exists(boundary_path):\n","            boundaries = np.load(boundary_path, allow_pickle=True)\n","            return list(boundaries)\n","        return []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2300,"status":"ok","timestamp":1733920176726,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"XHg6Xc4CoO82","outputId":"f748d801-5fa1-47ee-bad9-c27ef258f610"},"outputs":[],"source":["num_images = 10\n","split = 'train'\n","\n","# Load the dataset using BoundaryDataset class\n","dataset = BoundaryDataset(data_dir, split=split)\n","\n","print(f\"Data size: {len(dataset)}\")"]},{"cell_type":"markdown","metadata":{"id":"R-vv4up0L_pZ"},"source":["# ground truth 함께 확인\n","\n","```\n","# of test image : [:20] -> F1 (Recall / Precision)\n","Overall Evaluation Metrics Using a Single Best Threshold for All Images\n","```\n","\n","- ground truth[0] -> 0.917886 (0.848444 / 0.999709)\n","- ground truth[1] -> 0.885948 (0.795358 / 0.999828)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1733920125630,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"k_qWrvcJnz3v"},"outputs":[],"source":["random.seed(100)\n","selected_sample_names = random.sample(dataset.sample_names, min(num_images, len(dataset.sample_names)))\n","selected_sample_names = sorted(dataset.sample_names)[100:110]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":274807,"status":"ok","timestamp":1733920454169,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"LXJ5zfy61D2H","outputId":"a8f61047-1913-4aeb-e30a-cf7cd8b949f0"},"outputs":[],"source":["\n","data_dic = {}\n","# Plot multiple images and their boundaries\n","for selected_sample_name in dataset.sample_names:\n","\n","    data_dic[selected_sample_name] = ''\n","\n","    print(f\"Processing image: {split}/{selected_sample_name}\")\n","    image = dataset.read_image(selected_sample_name)\n","    boundaries = dataset.load_boundaries(selected_sample_name)\n","\n","    fig, ax = plt.subplots(1, len(boundaries) + 1, figsize=(6 * (len(boundaries) + 1), 6))\n","\n","    ax[0].imshow(image)\n","    ax[0].set_title(\"Original Image\")\n","    ax[0].axis(\"off\")\n","\n","    for i in range(len(boundaries)):\n","        ax[i + 1].imshow(boundaries[i], cmap='gray')\n","        ax[i + 1].set_title(f\"Boundary {i + 1}\")\n","        ax[i + 1].axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1733920134459,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"3BrcRqF_L9LI"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"hIdm2ogPs0Fi"},"source":["# ⭐️gaussian blur + median blur\n","\n","\n","```\n","[ (gblur kernelsize), mblur kernelsize, mblur의 blend 비율, (canny thre) ]\n","\n","# of test image : [:20] -> F1 (Recall / Precision)\n","Overall Evaluation Metrics Using a Single Best Threshold for All Images\n","-> ( Threshold  Recall     Precision  F1-Score)\n","\n","```\n","\n","- test02_0_2blur_all.npy : [ ?? ] -> 0.591017  \n","- test02_1_2blur_all.npy : [ ?? ] -> 0.588647 (0.611680 / 0.567285)\n","- test02_2_2blur_all.npy : [ (11,11), 21, 0.45, (3,80) ] -> 0.588586 (0.611739 / 0.567654)\n","\n","    [200] -> 0.549023 (0.610456 / 0.498824)\n","- test02_3_2blur_all.npy : [ (11,11), 17, 0.5, (3,80) ] -> 0.599114 (0.622844 / 0.577126)\n","\n","    [200] -> 0.554463 (0.613340 / 0.505900)\n","- test02_4_2blur_all.npy : [ (11,11), 17, 0.45, (5,95) ] -> 0.600955 (0.582339 / 0.620801) : 바운더리를 좀 더 찾아내야 하는 상황\n","\n","    [:100]으로 돌리니까 갑자기 (re0.853052  pre0.334845  F0.480918)  이러는데 하....-> precision이개낮음\n","\n","    [200] ->  0.477919  (0.850314 /0.332362)\n","- test02_5_2blur_all.npy : [ (11,11), 15, 0.45, (0,110) ] -> 0.588665 (0.538169 / 0.649618): thre2를 높게 줘서 확실한 엣지는 엣지로 박아두고, 나머지 픽셀은 이어져잇으면 엣지로 취급하는 방법...\n","\n","    [200] -> 0.547980 (0.538143  / 0.558183 )\n","- test02_6_2blur_all.npy : [ (11,11), 15, 0.45, (250,253) ] -> 0.158472 (0.087858 / 0.807389)  : 그냥 극단적으로 엣지를 없애서.. precision을 높였을 때 recall이 어케될지,, 오 완전 구려지넹.. F1 score라서 그냥 둘 다 높아야 한다...\n","- test02_7_2blur_all.npy : [ (11,11), 17, 0.5, (3,70) ] -> [200] 0.548656 (0.657777 / 0.470588)   : 미디안 좀 올려보고 싶음\n","- test02_8_2blur_all.npy : [ (11,11), 17, 0.6, (3,70) ] -> [200] 0.551136 (0.621892 / 0.494835)   \n","- test02_9_2blur_all.npy : [ (9,9), 17, 0.6, (3,70) ] -> [200] 0.539858 (0.685454 / 0.445278)\n","- test02_10_2blur_all.npy : [ (9,9), 17, 0.65, (15,90) -> [200] 0.549334 (0.572947 / 0.527590) :눈으로 봐서는 이제 모르겠다 하.. 얇은 엣지를 못찾고, 안 찾아도 될 디테일은 찾고..\n","- test02_11_2blur_all.npy : [ (9,9), 17, 0.65, (10,80) ] -> [200] 0.550453 (0.615713 / 0.497701)\n","- test02_12_2blur_all.npy : [ (9,9) 17, 0.6, (10,110) ] -> [200] 0.543039 (0.525870 / 0.561368)\n","- test02_13_2blur_all.npy : [ (9,9), 17, 0.6, (10,95) ] -> [200] 0.549547 (0.581407 / 0.520997)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"130Kj0lhJZZNOLO4uqAfInOpNEczeckAY"},"collapsed":true,"executionInfo":{"elapsed":9974,"status":"error","timestamp":1733089849365,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"B1lCAB06Aw5I","outputId":"379195be-3aea-45af-f10d-318c43b21ccf"},"outputs":[],"source":["data_dic = {}\n","for selected_sample_name in dataset.sample_names:\n","\n","  image = dataset.read_image(selected_sample_name)\n","  image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX) #normalize\n","  image = np.array(image)\n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","  # 블러링\n","  gblur_img  = cv2.GaussianBlur(image, (11, 11), sigmaX = 0, sigmaY = 0)\n","  mblur_img  = cv2.medianBlur(image, ksize=15)\n","\n","  # median blur + adaptive gaussian\n","  alpha = 0.45\n","  blend = cv2.addWeighted(gblur_img, 1-alpha, mblur_img, alpha, 0)\n","\n","  # Apply Canny Edge Detection\n","  canny_edge = cv2.Canny(blend, threshold1=0, threshold2=110)\n","\n","  #print(canny_edge)\n","  data_dic[selected_sample_name] = canny_edge\n","\n","\n","\n","  # Display the original and adaptive thresholded images\n","  plt.figure(figsize=(15, 12))\n","  plt.subplot(1, 5, 1)\n","  plt.title('origin')\n","  plt.imshow(image, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 2)\n","  plt.title('gaussian blur')\n","  plt.imshow(gblur_img, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 3)\n","  plt.title('median blur')\n","  plt.imshow(mblur_img, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 4)\n","  plt.title('blend(2+3)')\n","  plt.imshow(blend, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 5)\n","  plt.title('Canny')\n","  plt.imshow(canny_edge, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.show()\n","\n","np.save('/content/gdrive/MyDrive/CV/termProject/predictions/test02_14_2blur_all.npy', data_dic)\n"]},{"cell_type":"markdown","metadata":{"id":"nUJG_eswIJna"},"source":["- test02_14_2blur_all.npy : [ (9,9), 19, 0.6, 0.6 (3,70) ] -> [200]  0.539588 (0.666622 / 0.453220)\n","- test02_15_2blur_all.npy : [ (9,9), 15, 0.3, 0.6, (3,70) ] -> [200] 0.541598 (0.583468 / 0.505335)\n","- test02_16_2blur_all.npy : [ (9,9), 17, 0.4, 0.6, (3,90) ] -> [200] 0.534752 (0.531394 / 0.538153)\n","- test02_17_2blur_all.npy : [ (9,9), 11, 0.6, 0.6 (3,70) ] -> [200] 0.485807 (0.753858 / 0.358378)\n","- test02_18_2blur_all.npy : [ (9,9), 11, 0.6, 0.6 (3,70) ] -> [200]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":5235,"status":"error","timestamp":1733161842923,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"cm-_i3xsEskG","outputId":"2cac7833-1570-43a1-81e8-dd315121c481"},"outputs":[],"source":["data_dic = {}\n","for selected_sample_name in dataset.sample_names:\n","\n","  image = dataset.read_image(selected_sample_name)\n","  image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX) #normalize\n","  image = np.array(image)\n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","  #image = cv2.equalizeHist(image)\n","\n","  # 블러링\n","  gblur_img  = cv2.GaussianBlur(image, (9, 9), sigmaX = 0, sigmaY = 0)\n","  mblur_img  = cv2.medianBlur(image, ksize=11)\n","\n","  # median blur + adaptive gaussian\n","  alpha1 = 0.7\n","  blend = cv2.addWeighted(gblur_img, 1-alpha1, mblur_img, alpha1, 0)\n","\n","  alpha2 = 0.7\n","  blend = cv2.addWeighted(blend, 1-alpha2, mblur_img, alpha2, 0)\n","\n","\n","  # Apply Canny Edge Detection\n","  canny_edge = cv2.Canny(blend, threshold1=30, threshold2=90)\n","\n","\n","  black = np.zeros_like(image)\n","  contours, _ = cv2.findContours(blend, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n","  cv2.drawContours(black, contours, -1, (255, 0, 255), 2)\n","\n","\n","\n","  #print(canny_edge)\n","  data_dic[selected_sample_name] = canny_edge\n","\n","\n","\n","  # Display the original and adaptive thresholded images\n","  plt.figure(figsize=(15, 12))\n","  plt.subplot(1, 5, 1)\n","  plt.title('origin')\n","  plt.imshow(image, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 2)\n","  plt.title('gaussian blur')\n","  plt.imshow(gblur_img, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.title('median blur')\n","  plt.imshow(mblur_img, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 4)\n","  plt.title('blend(2+3)')\n","  plt.imshow(blend, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 5)\n","  plt.title('contour')\n","  plt.imshow(black, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.show()\n","\n","#np.save('/content/gdrive/MyDrive/CV/termProject/predictions/test02_18_2blur_all.npy', data_dic)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74TDsp_9szdU"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h2BkFY1uiNqV"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sexy7fk0iNsz"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"8ucf0CRXiS-h"},"source":["# ⭐️bilateral filter\n","blend ( mblur + bilater )\n","\n","- filter size -1 (자동값)으로 하면 원하는 대로 안 나옴. 구림\n","\n","https://wjh2307.tistory.com/11\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"mcJOTguNis0O"},"outputs":[],"source":["data_dic = {}\n","for selected_sample_name in dataset.sample_names:\n","\n","  image = dataset.read_image(selected_sample_name)\n","  image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX) #normalize\n","  image = np.array(image)\n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","  # bilateral\n","  bi = cv2.bilateralFilter(image, 80, 30, 30)\n","\n","  # Display the original and adaptive thresholded images\n","  plt.figure(figsize=(12, 9))\n","  plt.subplot(1, 2, 1)\n","  plt.title('origin')\n","  plt.imshow(image, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 2, 2)\n","  plt.title('bilateral')\n","  plt.imshow(bi, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.show()\n","  #np.save('/content/gdrive/MyDrive/CV/termProject/predictions/????????????.npy', data_dic)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fGCdYOxYs2OD"},"source":["#⭐️bilateral + mblur\n","생각보다 많이 구림. 뭔가 전반적으로 블러처리가 되어버려서 더 예민해진느낌..? 안잡아도 될 노이즈까지 잡힌다 자꾸 ㅜㅜ\n","\n","미디안필터사이즈를 좀 줄이고... 미디안 비율을 높이면? bi의 엣지만 조금 추가해주는 느낌으로\n","\n","\n","\n","```\n","[ mblur kernelsize, bilateral hyperparam, (mblur의)blend 비율, canny threshold ]\n","# of test image : [:20] -> F1 (Recall / Precision)\n","Overall Evaluation Metrics Using a Single Best Threshold for All Images\n","\n","```\n","\n","\n","\n","- test_bimblur01.npy : [ 7, (80,30,30), 0.9, (0,253) ] -> 0.531098 (0.608417 / 0.471215)     : 눈으로 보면 완전 너무 예민함. 근데 뭐야 둘 다 안 높고 걍 애매하네..\n","- test_bimblur06.npy : [9, (80,30,30), 0.9, (60,253) ] -> [200] 0.508616 (0.448007 / 0.588190)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1d5tk3Iqp2PvS_jbkDI6GYvx9gIkM6HMr"},"executionInfo":{"elapsed":438935,"status":"ok","timestamp":1732821410330,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"Bdowdhj9iNu7","outputId":"5fcbfb1f-7854-4677-c081-3edca49fb514"},"outputs":[],"source":["data_dic = {}\n","for selected_sample_name in dataset.sample_names:\n","\n","  image = dataset.read_image(selected_sample_name)\n","  image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX) #normalize\n","  image = np.array(image)\n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","  # 블러링\n","  gblur_img  = cv2.GaussianBlur(image, (11, 11), sigmaX = 0, sigmaY = 0)\n","  mblur_img  = cv2.medianBlur(image, ksize=9)\n","\n","  # bilateral\n","  bi = cv2.bilateralFilter(image, 80, 30, 30)\n","\n","\n","  # median blur + adaptive gaussian\n","  alpha = 0.9\n","  blend = cv2.addWeighted(bi, 1-alpha, mblur_img, alpha, 0)\n","\n","  # Apply Canny Edge Detection\n","  canny_edge = cv2.Canny(blend, threshold1=60, threshold2=253)\n","\n","  data_dic[selected_sample_name] = canny_edge\n","\n","\n","  # Display the original and adaptive thresholded images\n","  plt.figure(figsize=(15, 12))\n","  plt.subplot(1, 5, 1)\n","  plt.title('origin')\n","  plt.imshow(image, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 2)\n","  plt.title('bilateral')\n","  plt.imshow(bi, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 3)\n","  plt.title('median blur')\n","  plt.imshow(mblur_img, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 4)\n","  plt.title('blend(2+3)')\n","  plt.imshow(blend, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 5)\n","  plt.title('Canny')\n","  plt.imshow(canny_edge, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.show()\n","\n","\n","  np.save('/content/gdrive/MyDrive/CV/termProject/predictions/test_bimblur06.npy', data_dic)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BLEsGxAFzCVa"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"O_7Vj4KvaW-l"},"source":["# bilateral -> mblur -> ...\n","\n","bilateral을 해서, 엣지는 살리고 나머진 블러처리로 초벌을 한다.\n","\n","초벌 사진에다가 median blur를 취하면, 애매한 엣지들만 사라지는 것을 기대..\n","\n","```\n","[ (bilateral hyperparam), mblur kernelsize, (canny threshold) ]\n","# of test image : [:100] -> F1 (Recall / Precision)\n","Overall Evaluation Metrics Using a Single Best Threshold for All Images\n","\n","```\n","\n","- test_bimblur02.npy : [ (80,30,30), 7, (10,165) ] -> 0.499775 (0.532385 / 0.470930) 하 대체 뭐 어떻게 하라는 거 / 너무 디테일한 불필요한 애들도 잡힌다\n","- test_bimblur03.npy : [ (80,30,10), 11, (10,230) ] -> 0.465275 (0.376154 / 0.609736) : 아 recall이 엄청 낮게 잡혔네.....   \n","\n","  [200] ->  0.477489 (0.395731 / 0.601826)\n","- test_bimblur04.npy : [ (80,30,10), 7, (30,150) ] ->  0.535038   0.502438   0.518226  : recall을 올리기 위해 포착하는 엣지를 늘려보았음\n","\n","  [200] 0.517407 (0.556622 / 0.483353)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"elapsed":1904,"status":"error","timestamp":1733089201421,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"Z1oxrfoOzCXy","outputId":"e52b6371-2447-4301-c6a7-c81bdfeff011"},"outputs":[],"source":["data_dic = {}\n","for selected_sample_name in dataset.sample_names:\n","\n","  image = dataset.read_image(selected_sample_name)\n","  image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX) #normalize\n","  image = np.array(image)\n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","  # 블러링\n","  gblur_img  = cv2.GaussianBlur(image, (11, 11), sigmaX = 0, sigmaY = 0)\n","\n","\n","  # bilateral####\n","  bi = cv2.bilateralFilter(image, 80, 30, 10)\n","  mblur_img  = cv2.medianBlur(bi, ksize=7)\n","  ####\n","\n","  # median blur + adaptive gaussian\n","  alpha = 0.9\n","  blend = cv2.addWeighted(bi, 1-alpha, mblur_img, alpha, 0)\n","\n","  # Apply Canny Edge Detection\n","  canny_edge = cv2.Canny(mblur_img, threshold1=30, threshold2=150)\n","  ####\n","\n","  data_dic[selected_sample_name] = canny_edge\n","\n","\n","  # Display the original and adaptive thresholded images\n","  plt.figure(figsize=(15, 12))\n","  plt.subplot(1, 5, 1)\n","  plt.title('origin')\n","  plt.imshow(image, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 2)\n","  plt.title('bilateral')\n","  plt.imshow(bi, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 3)\n","  plt.title('bi->mblur')\n","  plt.imshow(mblur_img, cmap='gray')\n","  plt.axis('off')\n","\n","  # plt.subplot(1, 5, 4)\n","  # plt.title('blend(2+3)')\n","  # plt.imshow(blend, cmap='gray')\n","  # plt.axis('off')\n","\n","  plt.subplot(1, 5, 4)\n","  plt.title('Canny')\n","  plt.imshow(canny_edge, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.show()\n","\n","\n","  np.save('/content/gdrive/MyDrive/CV/termProject/predictions/test_bimblur04.npy', data_dic)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QI91nichzCaF"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iRJjZ56RzCeW"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"slZ5EQ7KDRi4"},"source":["# mblur -> bilateral -> ...\n","mblur로 자잘한 노이즈를 과감하게 없앤 다음에 bilateral로 엣지를 살리는 방법... ㅈㅂ\n","\n","```\n","[ mblur kernelsize, (bilateral hyperparam), (canny threshold) ]\n","# of test image : [:100] -> F1 (Recall / Precision)\n","Overall Evaluation Metrics Using a Single Best Threshold for All Images\n","\n","```\n","- test_bimblur05.npy [ 11, (80,30,10),(10,100) ] : 0.512931\n"," (0.452920 / 0.591275)   \n","- mblur랑 블랜드를 해서.. bi 때문에 흐려진 엣지를 살리고,, canny를 빡세게 주면 ...\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1gNmKyvz5WiKXdcVAaiZOi9JZB9JYMzsO"},"executionInfo":{"elapsed":453165,"status":"ok","timestamp":1732639916491,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"DbDbSYGslLi6","outputId":"536bb0cc-7886-41d1-a892-a7cfecc16322"},"outputs":[],"source":["data_dic = {}\n","for selected_sample_name in dataset.sample_names:\n","\n","  image = dataset.read_image(selected_sample_name)\n","  image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX) #normalize\n","  image = np.array(image)\n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","  # 블러링\n","  gblur_img  = cv2.GaussianBlur(image, (11, 11), sigmaX = 0, sigmaY = 0)\n","  mblur_img  = cv2.medianBlur(image, ksize=11)\n","\n","\n","  # bilateral####\n","  bi = cv2.bilateralFilter(mblur_img, 80, 30, 10)\n","  #mblur_img  = cv2.medianBlur(bi, ksize=3)\n","  ####\n","\n","  # median blur + adaptive gaussian\n","  alpha = 0.7\n","  blend = cv2.addWeighted(gblur_img, 1-alpha, mblur_img, alpha, 0)\n","\n","  # Apply Canny Edge Detection\n","  canny_edge = cv2.Canny(bi, threshold1=10, threshold2=100)\n","  ####\n","\n","  data_dic[selected_sample_name] = canny_edge\n","\n","\n","  # Display the original and adaptive thresholded images\n","  plt.figure(figsize=(15, 12))\n","  plt.subplot(1, 5, 1)\n","  plt.title('ori')\n","  plt.imshow(image, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 2)\n","  plt.title('mblur')\n","  plt.imshow(mblur_img, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 3)\n","  plt.title('mblur->bi')\n","  plt.imshow(bi, cmap='gray')\n","  plt.axis('off')\n","\n","  # plt.subplot(1, 5, 4)\n","  # plt.title('gb->bi->mb')\n","  # plt.imshow(mblur_img, cmap='gray')\n","  # plt.axis('off')\n","\n","  plt.subplot(1, 5, 4)\n","  plt.title('Canny')\n","  plt.imshow(canny_edge, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.show()\n","\n","\n","  np.save('/content/gdrive/MyDrive/CV/termProject/predictions/test_bimblur05.npy', data_dic)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k2YVZhvalLnk"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"j6Z70ChBlNwv"},"source":["# gblur -> bilateral -> ...\n","gaussian blur를 통해서 전체적으로 흐릿하게 만든다.\n","\n","그 후 bilateral을 통해서 그래도~!! 살아있는 엣지는 강조해준다. 를 기대. (근데 강도가 비슷한 엣지들이 사라진다 ㅜㅜ)\n","\n","```\n","[ (gblur size), (bilateral hyperparam), mblur kernelsize, mblur의blend비율, (canny threshold) ]\n","# of test image : [:100] -> F1 (Recall / Precision)\n","Overall Evaluation Metrics Using a Single Best Threshold for All Images\n","\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ZSZmEei8IH5hLiUsnCsa9Wb9B6b0Dc5N"},"executionInfo":{"elapsed":177407,"status":"error","timestamp":1732559944702,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"uDa-uVDplLcT","outputId":"7244f62f-1fe7-4977-df5e-d34a1c8443e8"},"outputs":[],"source":["data_dic = {}\n","for selected_sample_name in dataset.sample_names:\n","\n","  image = dataset.read_image(selected_sample_name)\n","  image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX) #normalize\n","  image = np.array(image)\n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","  # 블러링\n","  gblur_img  = cv2.GaussianBlur(image, (11, 11), sigmaX = 0, sigmaY = 0)\n","\n","\n","  # bilateral####\n","  bi = cv2.bilateralFilter(gblur_img, 80, 30, 10)\n","  mblur_img  = cv2.medianBlur(bi, ksize=3)\n","  ####\n","\n","  # median blur + adaptive gaussian\n","  alpha = 0.7\n","  blend = cv2.addWeighted(gblur_img, 1-alpha, mblur_img, alpha, 0)\n","\n","  # Apply Canny Edge Detection\n","  canny_edge = cv2.Canny(blend, threshold1=10, threshold2=100)\n","  ####\n","\n","  data_dic[selected_sample_name] = canny_edge\n","\n","\n","  # Display the original and adaptive thresholded images\n","  plt.figure(figsize=(15, 12))\n","  plt.subplot(1, 5, 1)\n","  plt.title('2+4 blend')\n","  plt.imshow(blend, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 2)\n","  plt.title('gblur')\n","  plt.imshow(gblur_img, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 3)\n","  plt.title('gblur->bi')\n","  plt.imshow(bi, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 4)\n","  plt.title('gb->bi->mb')\n","  plt.imshow(mblur_img, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 5)\n","  plt.title('Canny')\n","  plt.imshow(canny_edge, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.show()\n","\n","\n","  #np.save('/content/gdrive/MyDrive/CV/termProject/predictions/test_bigblur01.npy', data_dic)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oMCBVM07lLej"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kCFIntXHlLgp"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"cfIUx5rJzCmd"},"source":["# high-pass\n","\n","```\n","[ radius ]\n","Threshold  Recall     Precision  F1-Score  \n","```\n","- test_highpass01.npy [ 20 ] : 0.047619 / 0.499239 / 0.163614 / 0.246457"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1YocxMWQu7HgIZl771KOYvtpiP68_3xgA"},"executionInfo":{"elapsed":5291,"status":"ok","timestamp":1733163505097,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"F5kGh7I5zEWe","outputId":"8774866c-9d4a-45c9-fb05-4ed8685c2ce4"},"outputs":[],"source":["data_dic = {}\n","for selected_sample_name in dataset.sample_names:\n","\n","  image = dataset.read_image(selected_sample_name)\n","  image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX) #normalize\n","  image_np = np.array(image)\n","  image = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)\n","\n","  # Apply Fourier Transform to the original image\n","  f_transform = np.fft.fft2(image)\n","  f_shift = np.fft.fftshift(f_transform)  # Shift the zero frequency component to the center\n","\n","  # Calculate the magnitude spectrum\n","  magnitude_spectrum = 20 * np.log(np.abs(f_shift) + 1)\n","\n","  # Create a low-pass filter (circular mask)\n","  rows, cols = image.shape\n","  crow, ccol = rows // 2, cols // 2\n","\n","  # Create a circular mask centered at the middle of the frequency domain\n","  mask = np.zeros((rows, cols), np.uint8)\n","  Y, X = np.ogrid[:rows, :cols]\n","  distance_from_center = np.sqrt((X - ccol)**2 + (Y - crow)**2)\n","\n","  # Create a high-pass filter (circular mask)\n","  mask = np.ones((rows, cols), np.uint8)\n","  radius = 30\n","  mask[distance_from_center <= radius] = 0\n","\n","  # Apply the mask to the shifted frequency representation\n","  f_high_pass = f_shift * mask\n","\n","  # Calculate the magnitude spectrum of the filtered frequency\n","  magnitude_spectrum_high_pass = 20 * np.log(np.abs(f_high_pass) + 1)\n","\n","  # Inverse Fourier Transform to get the filtered image\n","  f_ishift = np.fft.ifftshift(f_high_pass)\n","  high_pass_img = np.fft.ifft2(f_ishift)\n","  high_pass_img = np.abs(high_pass_img)\n","\n","  data_dic[selected_sample_name] = high_pass_img\n","\n","  # Display the original image, filter, magnitude spectrum, and filtered image side by side\n","  plt.figure(figsize=(24, 6))\n","\n","  plt.subplot(1, 4, 1)\n","  plt.title('Original Grayscale Image')\n","  plt.imshow(image, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 4, 2)\n","  plt.title('High-pass Filter (Circular Mask)')\n","  plt.imshow(mask, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 4, 3)\n","  plt.title('Magnitude Spectrum After High-pass Filtering')\n","  plt.imshow(magnitude_spectrum_high_pass, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 4, 4)\n","  plt.title('High-pass Filtered Image')\n","  plt.imshow(high_pass_img, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.show()\n","\n","\n","  #np.save('/content/gdrive/MyDrive/CV/termProject/predictions/test_highpass01.npy', data_dic)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1waol3EGurmcbAj2COrMqDNLFarhcYxB3"},"executionInfo":{"elapsed":7021,"status":"ok","timestamp":1733172484910,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"KcqbG9XXCs4P","outputId":"4dc1e95a-2443-4518-a4e4-b95adc9a5c51"},"outputs":[],"source":["data_dic = {}\n","for selected_sample_name in dataset.sample_names:\n","\n","    image = dataset.read_image(selected_sample_name)\n","    image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)  # normalize\n","    image_np = np.array(image)\n","    image = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply Fourier Transform to the original image\n","    f_transform = np.fft.fft2(image)\n","    f_shift = np.fft.fftshift(f_transform)  # Shift the zero frequency component to the center\n","\n","    # Calculate the magnitude spectrum\n","    magnitude_spectrum = 20 * np.log(np.abs(f_shift) + 1)\n","\n","    # Create a low-pass filter (circular mask)\n","    rows, cols = image.shape\n","    crow, ccol = rows // 2, cols // 2\n","\n","    # Create a circular mask centered at the middle of the frequency domain\n","    mask = np.zeros((rows, cols), np.uint8)\n","    Y, X = np.ogrid[:rows, :cols]\n","    distance_from_center = np.sqrt((X - ccol) ** 2 + (Y - crow) ** 2)\n","\n","    # Create a high-pass filter (circular mask)\n","    mask = np.ones((rows, cols), np.uint8)\n","    radius = 30\n","    mask[distance_from_center <= radius] = 0\n","\n","    # Apply the mask to the shifted frequency representation\n","    f_high_pass = f_shift * mask\n","\n","    # Calculate the magnitude spectrum of the filtered frequency\n","    magnitude_spectrum_high_pass = 20 * np.log(np.abs(f_high_pass) + 1)\n","\n","    # Inverse Fourier Transform to get the filtered image\n","    f_ishift = np.fft.ifftshift(f_high_pass)\n","    high_pass_img = np.fft.ifft2(f_ishift)\n","    high_pass_img = np.abs(high_pass_img)\n","\n","    # Convert high-pass image to uint8\n","    high_pass_img_uint8 = np.uint8(high_pass_img)\n","\n","    # Apply adaptive thresholding\n","    adaptive_thresh_mean = cv2.adaptiveThreshold(\n","        high_pass_img_uint8, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 101, 17)\n","\n","    # Black image for drawing contours\n","    black = np.zeros(image.shape, np.uint8)\n","\n","    # Find and draw contours\n","    contours, _ = cv2.findContours(adaptive_thresh_mean, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n","    cv2.drawContours(black, contours, -1, 255, 3)\n","\n","    # Save result to dictionary\n","    data_dic[selected_sample_name] = black\n","\n","    # Display results\n","    plt.figure(figsize=(24, 6))\n","\n","    plt.subplot(1, 4, 1)\n","    plt.title('Original Grayscale Image')\n","    plt.imshow(image, cmap='gray')\n","    plt.axis('off')\n","\n","    plt.subplot(1, 4, 2)\n","    plt.title('High-pass Filter (Circular Mask)')\n","    plt.imshow(mask, cmap='gray')\n","    plt.axis('off')\n","\n","    plt.subplot(1, 4, 3)\n","    plt.title('Magnitude Spectrum After High-pass Filtering')\n","    plt.imshow(magnitude_spectrum_high_pass, cmap='gray')\n","    plt.axis('off')\n","\n","    plt.subplot(1, 4, 4)\n","    plt.title('Black')\n","    plt.imshow(black, cmap='gray')\n","    plt.axis('off')\n","\n","    plt.show()\n","\n","# Save data dictionary if needed\n","# np.save('/content/gdrive/MyDrive/CV/termProject/predictions/test_highpass01.npy', data_dic)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"shx4nIwsHQoA"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3R4MCv6RHQtR"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"iavIT9TF2kCm"},"source":["# high pass 결과에다가 median 적용?ㅋㅋ"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":233},"executionInfo":{"elapsed":321,"status":"error","timestamp":1732648252779,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"4xOluwKg2jcL","outputId":"c5287cfc-0de7-4f79-c7cb-800e21ca4f9c"},"outputs":[],"source":["data_dic = {}\n","for selected_sample_name in dataset.sample_names:\n","\n","  image = dataset.read_image(selected_sample_name)\n","  image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX) #normalize\n","  image_np = np.array(image)\n","  image = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)\n","\n","  # Apply Fourier Transform to the original image\n","  f_transform = np.fft.fft2(image)\n","  f_shift = np.fft.fftshift(f_transform)  # Shift the zero frequency component to the center\n","\n","  # Calculate the magnitude spectrum\n","  magnitude_spectrum = 20 * np.log(np.abs(f_shift) + 1)\n","\n","  # Create a low-pass filter (circular mask)\n","  rows, cols = image.shape\n","  crow, ccol = rows // 2, cols // 2\n","\n","  # Create a circular mask centered at the middle of the frequency domain\n","  mask = np.zeros((rows, cols), np.uint8)\n","  Y, X = np.ogrid[:rows, :cols]\n","  distance_from_center = np.sqrt((X - ccol)**2 + (Y - crow)**2)\n","\n","  # Create a high-pass filter (circular mask)\n","  mask = np.ones((rows, cols), np.uint8)\n","  radius = 20\n","  mask[distance_from_center <= radius] = 0\n","\n","  # Apply the mask to the shifted frequency representation\n","  f_high_pass = f_shift * mask\n","\n","  # Calculate the magnitude spectrum of the filtered frequency\n","  magnitude_spectrum_high_pass = 20 * np.log(np.abs(f_high_pass) + 1)\n","\n","  # Inverse Fourier Transform to get the filtered image\n","  f_ishift = np.fft.ifftshift(f_high_pass)\n","  high_pass_img = np.fft.ifft2(f_ishift)\n","  high_pass_img = np.abs(high_pass_img)\n","\n","  high_pass_img = cv2.normalize(high_pass_img, None, 0, 255, cv2.NORM_MINMAX)\n","  final = cv2.medianBlur(high_pass_img, ksize=3)\n","\n","  data_dic[selected_sample_name] = final\n","\n","  # Display the original image, filter, magnitude spectrum, and filtered image side by side\n","  plt.figure(figsize=(24, 6))\n","\n","  plt.subplot(1, 4, 1)\n","  plt.title('Original Grayscale Image')\n","  plt.imshow(image, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 4, 2)\n","  plt.title('High-pass Filter')\n","  plt.imshow(final, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 4, 3)\n","  plt.title('fiinal')\n","  plt.imshow(high_pass_img, cmap='gray')\n","  plt.axis('off')\n","\n","  # plt.subplot(1, 4, 4)\n","  # plt.title('final')\n","  # plt.imshow(final, cmap='gray')\n","  # plt.axis('off')\n","\n","  plt.show()\n","\n","\n","  #np.save('/content/gdrive/MyDrive/CV/termProject/predictions/test_highpass01.npy', data_dic)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mWB9Pezv2je3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SFXJs5PA2jhX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kVv6eyU02jj5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sZeLSdtN2jmR"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9zusk5r2joK"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"y2ayFp-kHRZD"},"source":["# mblur + highpass filter\n","\n","mblur로 두꺼운 엣지만 남기고, highpass filter로 형태만 추출하고픈 마음\n","개ㅐㅐㅐㅐㅐㅐㅐㅐㅐㅐ구림\n","\n","```\n","[ mblurkernelsize , radius ]\n","```\n","\n","- test_mblurhigh01.npy ["]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1vd5Rx3uFgdVztBSixyzZjb3zaacpXJbd"},"executionInfo":{"elapsed":87582,"status":"error","timestamp":1732636475160,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"5yBzZIBCHQxM","outputId":"02be1e42-6c68-43d7-ed9e-6a34ec9a2cf4"},"outputs":[],"source":["data_dic = {}\n","for selected_sample_name in dataset.sample_names:\n","\n","  image = dataset.read_image(selected_sample_name)\n","  image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX) #normalize\n","  image_np = np.array(image)\n","  image = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)\n","\n","  mblur_img  = cv2.medianBlur(image, ksize=9)\n","\n","  # Apply Fourier Transform to the original image\n","  f_transform = np.fft.fft2(mblur_img)\n","  f_shift = np.fft.fftshift(f_transform)  # Shift the zero frequency component to the center\n","\n","  # Calculate the magnitude spectrum\n","  magnitude_spectrum = 20 * np.log(np.abs(f_shift) + 1)\n","\n","  # Create a low-pass filter (circular mask)\n","  rows, cols = mblur_img.shape\n","  crow, ccol = rows // 2, cols // 2\n","\n","  # Create a circular mask centered at the middle of the frequency domain\n","  mask = np.zeros((rows, cols), np.uint8)\n","  Y, X = np.ogrid[:rows, :cols]\n","  distance_from_center = np.sqrt((X - ccol)**2 + (Y - crow)**2)\n","\n","  # Create a high-pass filter (circular mask)\n","  mask = np.ones((rows, cols), np.uint8)\n","  radius = 30\n","  mask[distance_from_center <= radius] = 0\n","\n","  # Apply the mask to the shifted frequency representation\n","  f_high_pass = f_shift * mask\n","\n","  # Calculate the magnitude spectrum of the filtered frequency\n","  #magnitude_spectrum_high_pass = 20 * np.log(np.abs(f_high_pass) + 1)\n","\n","  # Inverse Fourier Transform to get the filtered image\n","  f_ishift = np.fft.ifftshift(f_high_pass)\n","  high_pass_img = np.fft.ifft2(f_ishift)\n","  high_pass_img = np.abs(high_pass_img)\n","\n","  data_dic[selected_sample_name] = high_pass_img\n","\n","  # Display the original image, filter, magnitude spectrum, and filtered image side by side\n","  plt.figure(figsize=(24, 6))\n","\n","  plt.subplot(1, 4, 1)\n","  plt.title('Original Grayscale Image')\n","  plt.imshow(image, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 4, 2)\n","  plt.title('median blur')\n","  plt.imshow(mblur_img, cmap='gray')\n","  plt.axis('off')\n","\n","  # plt.subplot(1, 4, 3)\n","  # plt.title('Magnitude Spectrum After High-pass Filtering')\n","  # plt.imshow(magnitude_spectrum_high_pass, cmap='gray')\n","  # plt.axis('off')\n","\n","  plt.subplot(1, 4, 3)\n","  plt.title('High-pass Filtered Image')\n","  plt.imshow(high_pass_img, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.show()\n","\n","\n","  np.save('/content/gdrive/MyDrive/CV/termProject/predictions/test_mblurhigh01.npy', data_dic)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_uyok_6yHQ1b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b7y3pDovNG5s"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_DyaWGhPNHiD"},"source":["# graph cut"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":12017,"status":"ok","timestamp":1733520748388,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"t2xZKjJ7NG8K","outputId":"7e8c37e0-a586-4f3c-f456-badce8afe4d3"},"outputs":[],"source":["from skimage import data, color, graph\n","from skimage.color import rgb2lab, label2rgb\n","from skimage.segmentation import slic, mark_boundaries\n","\n","data_dic = {}\n","for selected_sample_name in dataset.sample_names:\n","\n","  image = dataset.read_image(selected_sample_name)\n","  image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX) #normalize\n","  image = np.array(image)\n","  gimage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","  # 블러링\n","  gblur_img  = cv2.GaussianBlur(image, (3, 3), sigmaX = 0, sigmaY = 0)\n","  mblur_img  = cv2.medianBlur(gimage, ksize=19)\n","  # median blur + adaptive gaussian\n","  alpha1 = 0.5\n","  #blur_blend = cv2.addWeighted(gblur_img, 1-alpha1, mblur_img, alpha1, 0)\n","\n","\n","###############\n","  # Apply SLIC SuperPixel segmentation -> 픽셀 개수를 좀 줄여주는 역할,,,,\n","  segments = slic(gblur_img, n_segments=100, compactness=20, sigma=0.8)\n","  # compactness가 커지면 굵직굵직해짐\n","\n","  # Build Region Adjacency Graph (RAG)\n","  rag = graph.rag_mean_color(image, segments, mode='similarity')\n","\n","  # Apply Normalized Cut\n","  labels = graph.cut_normalized(segments, rag)\n","  print(\"# Unique Labels:\", len(np.unique(labels)))\n","\n","  segmented_image = label2rgb(labels, image, kind='avg', bg_label=0) # rgb label로 줌\n","  seg_image = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n","\n","  alpha2 = 0.2\n","  #blend = cv2.addWeighted(blur_blend, 1-alpha2, seg_image, alpha2, 0)\n","\n","\n","############\n","  # Apply Canny Edge Detection\n","  canny_edge = cv2.Canny(segmented_image, threshold1=70, threshold2=150)\n","\n","  #print(canny_edge)\n","  data_dic[selected_sample_name] = canny_edge\n","\n","\n","\n","  # Display the original and adaptive thresholded images\n","  # plt.figure(figsize=(18, 6))\n","  # plt.subplot(2, 6, 1)\n","  # plt.title('origin')\n","  # plt.imshow(image, cmap='gray')\n","  # plt.axis('off')\n","\n","  # plt.subplot(2, 6, 2)\n","  # plt.title('gaussian blur')\n","  # plt.imshow(gblur_img, cmap='gray')\n","  # plt.axis('off')\n","\n","  # plt.subplot(2, 6, 3)\n","  # plt.title('median blur')\n","  # plt.imshow(mblur_img, cmap='gray')\n","  # plt.axis('off')\n","\n","  plt.subplot(1, 2, 1)\n","  plt.title('Graph Cut')\n","  plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n","  plt.axis('off')\n","\n","  # plt.subplot(2, 2, 1)\n","  # plt.title('blend(2+3+4)')\n","  # plt.imshow(blend, cmap='gray')\n","  # plt.axis('off')\n","\n","  plt.subplot(1, 2, 2)\n","  plt.title('Canny on Graph cut')\n","  plt.imshow(canny_edge, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.show()\n","\n","\n","  #np.save('/content/gdrive/MyDrive/CV/termProject/predictions/test_graph.npy', data_dic)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CgMjYJpNG-j"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dlqq21Y9NHBD"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"TG7IKYADVFFp"},"source":["# 리더보드 코드"]},{"cell_type":"markdown","metadata":{"id":"4EzoWmb7dXeK"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OrbU0kbJWnGg"},"outputs":[],"source":["def blend4(image, threshold1, threshold2) :\n","  g_image1 = cv2.GaussianBlur(image, (15, 15), 0)\n","  g_image2 = cv2.GaussianBlur(image, (29, 29), 0)\n","\n","  m_image1 = cv2.medianBlur(image, 15)\n","  m_image2 = cv2.medianBlur(image, 29)\n","\n","  alpha = 0.3\n","  blended1 = cv2.addWeighted(g_image1, alpha, m_image1, 1-alpha, 0, dst=None, dtype=None)\n","\n","  alpha2 = 0.6\n","  blended2 = cv2.addWeighted(g_image2, alpha2, m_image2, 1-alpha2, 0, dst=None, dtype=None)\n","\n","  alpha3 = 0.6\n","  blended3 = cv2.addWeighted(blended1, alpha3, blended2, 1-alpha3, 0, dst=None, dtype=None)\n","  edges3 = cv2.Canny(blended3, threshold1, threshold2, apertureSize=3)\n","\n","  return blended3, edges3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sJWU37PrWrh4"},"outputs":[],"source":["import sys\n","\n","def preprocess_image(image):\n","    \"\"\"Reshape the image to a 2D array of pixels and 3 color values (RGB) and convert to float.\"\"\"\n","    pixel_values = image.reshape((-1, 3))\n","    return np.float32(pixel_values)\n","\n","def perform_kmeans_clustering(pixel_values, k=3):\n","    \"\"\"Perform k-means clustering on the pixel values.\"\"\"\n","    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n","    compactness, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n","    return compactness, labels, np.uint8(centers)\n","\n","def create_segmented_image(pixel_values, labels, centers):\n","    \"\"\"Create a segmented image using the cluster centroids.\"\"\"\n","    segmented_image = centers[labels.flatten()]\n","    return segmented_image.reshape(image.shape)\n","\n","def ensemble_edges(edge1, edge2, method='or', alpha=0.5, beta=0.5):\n","    if method == 'or':\n","        # 픽셀 단위 OR 연산 (하나라도 경계인 경우 유지)\n","        combined_edges = cv2.bitwise_or(edge1, edge2)\n","    elif method == 'and':\n","        # 픽셀 단위 AND 연산 (두 결과가 공통으로 경계인 경우만 유지)\n","        combined_edges = cv2.bitwise_and(edge1, edge2)\n","    elif method == 'weighted':\n","        # 가중치 블렌딩\n","        combined_edges = cv2.addWeighted(edge1, alpha, edge2, beta, 0)\n","    else:\n","        raise ValueError(\"method는 'or', 'and', 또는 'weighted' 중 하나여야 합니다.\")\n","\n","    return combined_edges\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1j-Uf1lV92b06_ZtdqoI4TOGMSemyfuSM"},"executionInfo":{"elapsed":300287,"status":"ok","timestamp":1733159969975,"user":{"displayName":"wooyoung","userId":"01523881118321271540"},"user_tz":-540},"id":"zpXwMu8iNHIc","outputId":"dee63401-8ae8-43b9-d2fe-e41abc92a414"},"outputs":[],"source":["for selected_sample_name in dataset.sample_names:\n","    #print(f\"Processing image {num} : {split}/{selected_sample_name}\")\n","    image = dataset.read_image(selected_sample_name)\n","    image_np = np.array(image)\n","    image = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n","    blended, edge = blend4(image, 30 ,50)\n","    pixel_values = preprocess_image(blended)\n","\n","    k=3\n","    # compactness is the sum of squared distance from each point to their corresponding centers\n","    compactness, labels, centers = perform_kmeans_clustering(pixel_values, k)\n","    # create the segmented image\n","    segmented_image = create_segmented_image(pixel_values, labels, centers)\n","\n","    edge2 = cv2.Canny(segmented_image, 50, 100, apertureSize=3)\n","    # 특정 클러스터의 경계 감지\n","    #edge2 = highlight_cluster_edges(segmented_image, labels, cluster_to_highlight, 130, 180)\n","\n","    # 앙상블 적용\n","    combined_or = ensemble_edges(edge, edge2, method='or')\n","    combined_and = ensemble_edges(edge, edge2, method='and')\n","    combined_weighted = ensemble_edges(edge, edge2, method='weighted', alpha=0.6, beta=0.4)\n","\n","    threshold_value = 152.5\n","    _, strong_edges = cv2.threshold(combined_weighted, threshold_value, 255, cv2.THRESH_BINARY)\n","\n","    combined_weighted = ensemble_edges(edge, strong_edges, method='weighted', alpha=0.6, beta=0.4)\n","\n","    # 결과 시각화\n","    plt.figure(figsize=(18, 6))\n","    plt.subplot(1, 4, 1)\n","    plt.title(\"Original Image\")\n","    plt.imshow(image, cmap=\"gray\")\n","    plt.axis(\"off\")\n","\n","    plt.subplot(1, 4, 2)\n","    plt.title(\"combined_weighted\")\n","    plt.imshow(combined_weighted, cmap=\"gray\")\n","    plt.axis(\"off\")\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w_RBQ1eSNHJO"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"xHi8BO9jdbIJ"},"source":["## Try 3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xz-EhpJidZxo"},"outputs":[],"source":["data_dic = {}\n","for selected_sample_name in dataset.sample_names:\n","\n","  image = dataset.read_image(selected_sample_name)\n","  image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX) #normalize\n","  image = np.array(image)\n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","  # 블러링\n","  gblur_img  = cv2.GaussianBlur(image, (11, 11), sigmaX = 0, sigmaY = 0)\n","  mblur_img  = cv2.medianBlur(image, ksize=15)\n","\n","  # median blur + adaptive gaussian\n","  alpha = 0.45\n","  blend = cv2.addWeighted(gblur_img, 1-alpha, mblur_img, alpha, 0)\n","\n","  # Apply Canny Edge Detection\n","  canny_edge = cv2.Canny(blend, threshold1=0, threshold2=110)\n","\n","  #print(canny_edge)\n","  data_dic[selected_sample_name] = canny_edge\n","\n","\n","\n","  # Display the original and adaptive thresholded images\n","  plt.figure(figsize=(15, 12))\n","  plt.subplot(1, 5, 1)\n","  plt.title('origin')\n","  plt.imshow(image, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 2)\n","  plt.title('gaussian blur')\n","  plt.imshow(gblur_img, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 3)\n","  plt.title('median blur')\n","  plt.imshow(mblur_img, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 4)\n","  plt.title('blend(2+3)')\n","  plt.imshow(blend, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(1, 5, 5)\n","  plt.title('Canny')\n","  plt.imshow(canny_edge, cmap='gray')\n","  plt.axis('off')\n","\n","  plt.show()\n","\n","np.save('/content/gdrive/MyDrive/CV/termProject/predictions/test02_14_2blur_all.npy', data_dic)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Ha4DAE8daEk"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kESd73fhdaHC"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4MmR7qyEdaJO"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPaxuJm1ATDu3W3aK0aUYqg","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
